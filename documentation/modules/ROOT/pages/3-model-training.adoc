= 3. モデルのトレーニング - 15 minutes
:imagesdir: ../assets/images

このセクションでは、データ サイエンティストがモデルをどのようにトレーニングしているかを見ていきます。これは非常に単純な例ですが、ワークフローの基本を説明します。

* サンドボックス ノートブックを開いたままの場合は、まず閉じてください。

image::close_sandbox.png[]

ワークショップの残りの部分ではデータ サイエンス プロジェクトを使用するため、Jupyter ノートブック環境とポッドもシャットダウンする必要があります。

* ブラウザーで OpenShift AI ダッシュボード タブを開いている場合は、そこにアクセスしてください。その後、単純に JupyterLab タブを閉じ、ダッシュボードで **Stop notebook server** を選択します。

image::stop_notebook_server.png[]

* OpenShift AI ダッシュボードを閉じた場合は、 https://rhods-dashboard-redhat-ods-applications.%SUBDOMAIN%[ここ^] にアクセスするか、 **File->Hub Control Panel** をクリックして Jupyter から再度開くことができます。

image::hub_panel.png[]

ダッシュボードのタブが再度開きます。ここから、前述のようにノートブック環境を停止できます。これで、データ サイエンス プロジェクトに取り組む準備が整いました。

== 3.1. データサイエンスプロジェクト

まず、モデルのトレーニング、モデルの提供、アプリケーションのデプロイメントなど、すべての作業を整理するデータ サイエンス プロジェクトが必要です。前に述べたように、データ サイエンス プロジェクトは実際には OpenShift プロジェクトですが、作成するために OpenShift AI 環境を離れる必要はありません。

=== 3.1.1. DSP の作成

*  **Data Science Projects** に移動し、 **Create data science project** を選択します。

image::create_dsp.png[]

* ポップアップ ウィンドウに次の値を入力します。これは OpenShift の表示名となり、リソース名は自動的にサニタイズされて作成されます。

* *Name*: `%USERID% data science project`
* *Resource name*: `%USERID%-data-science-project`
* *Description*: `データサイエンスに初めて挑戦してみます！`

image::create_dsp_modal.png[]

ここで、興味があれば *OpenShift コンソール* を見てみましょう。

* Web ブラウザから https://console-openshift-console.%SUBDOMAIN%/k8s/cluster/projects/%USERID%-data-science-project[Data Science Project^] にアクセスします。

* これまで OpenShift クラスターにログインしたことがない場合は、次の認証情報を使用します。 OpenShift はすでに https://access.redhat.com/products/red-hat-single-sign-on/[Red Hat Single Sign On^] と統合されています。

image::sso_login.png[openshift_login]

*  Login using your credentials:

** Username: `%USERID%`
** Password: `{openshift-password}`

* プロジェクトが実際に作成されたことがわかります。

image::my_dsp_console.png[]

=== 3.1.2. DSP の使用

データ サイエンス プロジェクトには、さまざまなセクションがあります。

* ワークベンチは開発環境です。これらは JupyterLab をベースにすることもできますが、VS Code や RStudio などの他のタイプの IDE をベースにすることもできます。ワークベンチは必要なだけ作成でき、同時に実行できます。
* クラスター ストレージは永続ボリューム クレーム (PVC) であり、ノートブックやデータの保存に使用できる永続ストレージ スペースです。ここから直接作成し、必要に応じてワークベンチにマウントできます。作業内容を保存するために、デフォルトのクラスターストレージ (PVC) が新しいワークベンチで常に自動的に作成されることに注意してください。
* データ接続は、リモート データのための構成です。現時点では、S3 互換のオブジェクト ストレージのみがサポートされています。後でこの機能を使用して、モデルのストレージを構成します。
* 最後に、モデルサーバーはモデルを提供するために使用されます。しかし、それは後で取っておきましょう。

ここでは、Tensorflow と連携してモデルをトレーニングするための新しいワークベンチを作成しましょう。

* **Create workbench** を選択します。

image::create_workbench.png[]

* 名前を付け **Tensorflow** イメージ、バージョン **2023.1** 、デプロイ サイズ **Small** 、クラスター ストレージ スペース **1GB** を選択します。これで十分です。

image::create_workbench_1.png[]
image::create_workbench_2.png[]

* そしてもちろん、 **Create workbench** を選択します。

image::create_workbench_click.png[]

* ワークベンチが作成され、最初は **Starting state** です。

image::workbench_starting.png[]

このトグルを使用すると、後でこの環境を簡単に開始/停止できます。

* 準備が完了すると、状態が **Running** に変わり、 **Open** を選択して環境に移動できます。

image::workbench_running.png[]

* 認証して権限を許可すると、使い慣れた JupyterLab 環境に戻ります。

image::workbench_jl.png[]

== 3.2. モデルのトレーニング

本格的な作業を行う準備が整いました。

* もう一度、左側の Git メニューに移動します。

image::git.png[]

* 次に `Clone a Repository` を選択します。

image::git_clone.png[]

* URL https://github.com/team-ohc-jp-place/mad_m6_workshop を入力し、,  `Clone` を選択します。

image::clone_repo.png[]

* この操作は数秒かかります。その後、ダブルクリックして、新しく作成したフォルダー **mad_m6_workshop** に移動できます。

image::open_mad_workshop.png[]

*  `mad_m6_workshop` フォルダーで、 `02_model_training_basics` ファイルを開きます。

* ノートブックの手順に従い、各セルを実行します。 `pip install` が実行されるセルを実行すると、エラー メッセージが表示される場合がありますが、無視しても問題ありません。

image::run_cell.png[]
